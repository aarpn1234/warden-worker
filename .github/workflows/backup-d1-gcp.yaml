name: Backup D1 Database to gcp

on:
  schedule:
    - cron: "0 6 * * *"
  workflow_dispatch:

env:
  BACKUP_RETENTION_DAYS: 30

jobs:
  backup-production:
    name: Backup Production D1 Database
    runs-on: ubuntu-latest

    steps:
      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT

      - name: Install wrangler
        run: npm install -g wrangler

      - name: Get D1 Database Name
        id: db_name
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          DB_NAME=$(npx wrangler d1 list --json | jq -r '.[] | select(.uuid == "${{ secrets.D1_DATABASE_ID }}") | .name')
          if [ -z "$DB_NAME" ]; then
            echo "❌ Error: Could not find database with D1_DATABASE_ID"
            exit 1
          fi
          echo "db_name=$DB_NAME" >> $GITHUB_OUTPUT

      - name: Export D1 Database
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "Exporting D1 database..."
          npx wrangler d1 export "${{ steps.db_name.outputs.db_name }}" \
            --remote \
            --output=backup.sql

          gzip backup.sql
          echo "Backup compressed: backup.sql.gz"
          ls -lh backup.sql.gz

      - name: Encrypt backup (optional)
        env:
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            echo "Encrypting backup with AES-256..."
            openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
              -in backup.sql.gz \
              -out "vault1_prod_${{ steps.date.outputs.date }}.sql.gz.enc" \
              -pass pass:"$BACKUP_ENCRYPTION_KEY"
            rm backup.sql.gz
          else
            mv backup.sql.gz "vault1_prod_${{ steps.date.outputs.date }}.sql.gz"
          fi

      # ------------------------------------------------------
      # Google Cloud authentication
      # ------------------------------------------------------
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          install_components: gsutil

      - name: Upload to GCP Cloud Storage
        env:
          BACKUP_ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
        run: |
          if [ -n "$BACKUP_ENCRYPTION_KEY" ]; then
            FILE_NAME="vault1_prod_${{ steps.date.outputs.date }}.sql.gz.enc"
          else
            FILE_NAME="vault1_prod_${{ steps.date.outputs.date }}.sql.gz"
          fi

          echo "Uploading $FILE_NAME to Google Cloud Storage..."
          gsutil cp "$FILE_NAME" "gs://$GCS_BUCKET/$FILE_NAME"
          echo "✅ Upload complete."

      - name: Clean up old backups in GCP Cloud Storage
        env:
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          BACKUP_RETENTION_DAYS: ${{ env.BACKUP_RETENTION_DAYS }}
        run: |
          CUTOFF_DATE=$(date -d "-${BACKUP_RETENTION_DAYS} days" +%Y-%m-%d)
          echo "Cleaning up backups older than $CUTOFF_DATE (retention: ${BACKUP_RETENTION_DAYS} days)..."

          # 列出所有符合条件的备份文件
          for file_url in $(gsutil ls "gs://$GCS_BUCKET/vault1_prod_*.sql.gz*"); do
            if [[ -n "$file_url" && "$file_url" != *"TOTAL"* ]]; then
              # 获取文件名并从中提取日期
              filename=$(basename "$file_url")
              
              # 从文件名中提取日期部分 (格式: vault1_prod_YYYY-MM-DD_HH-MM-SS.sql.gz.enc)
              file_date_part=$(echo "$filename" | sed 's/vault1_prod_\([0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}\).*/\1/')
              
              # 验证提取的日期格式是否正确
              if [[ "$file_date_part" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]; then
                # 比较日期
                if [[ "$file_date_part" < "$CUTOFF_DATE" ]]; then
                  echo "Deleting old backup: $file_url (date: $file_date_part)"
                  gsutil rm "$file_url"
                else
                  echo "Keeping backup: $filename (date: $file_date_part)"
                fi
              else
                echo "Skipping file with unrecognized date format: $filename"
              fi
            fi
          done

          echo "✅ Old backup cleanup complete."
